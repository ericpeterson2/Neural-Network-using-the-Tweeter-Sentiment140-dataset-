{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9973c6df",
   "metadata": {
    "id": "9973c6df"
   },
   "source": [
    "### Outline\n",
    "#### 1. Introduction \n",
    "#### 2. Load sentiment dataset\n",
    "#### 3. Pre-process\n",
    "#### 4. Logistic Regression\n",
    "#### 5. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273058b6",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2062727",
   "metadata": {},
   "source": [
    "During this project was developed three machine learning and data mining methods to solve the\n",
    "problem of classifying the polarity of tweets (binary classes) using the Sentiment140 dataset. This work\n",
    "explores the use of the logistic regression classifier model and two neural networks, Long Short-Term\n",
    "Memory (LSTM) and Convolutional Neural Networks (CNN). \n",
    "\n",
    "The practice of aiming to deliver a high\n",
    "accuracy score whilst pre-processing and fine-tuning the hyperparameters of these models allows us to\n",
    "become familiar with each of these algorithms and its nuances both theoretically and in practice when\n",
    "applied to Natural Language Processing (NLP). \n",
    "\n",
    "The results show that the CNN model was the best\n",
    "performer in terms of prediction accuracy and had the shortest run time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf0843",
   "metadata": {
    "id": "91bf0843"
   },
   "source": [
    "### 2. Load sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f0c14b",
   "metadata": {
    "id": "f5f0c14b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "S9Vna-3FHLgk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9Vna-3FHLgk",
    "outputId": "02f24338-925b-40b3-8b77-c6cfcd916409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 133 kB 7.1 MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "HPetocyUEWLO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPetocyUEWLO",
    "outputId": "98f8478b-e2a7-4453-9b09-225bf458a8b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ericp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Loading the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import keras_tuner as kt\n",
    "from keras_tuner.tuners import RandomSearch, hyperband, BayesianOptimization\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c46f28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "78c46f28",
    "outputId": "aa2d3f6e-29a5-4508-88b9-ae6414d0f13d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-69ee23ff-a18f-4690-b63e-6f01744a7b67\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69ee23ff-a18f-4690-b63e-6f01744a7b67')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-69ee23ff-a18f-4690-b63e-6f01744a7b67 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-69ee23ff-a18f-4690-b63e-6f01744a7b67');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "\n",
    "#Change the 'path', for the path of the dataset uploaded in google colab\n",
    "path = '/content/sentiment140.csv'\n",
    "\n",
    "data = pd.read_csv(path, encoding='latin-1', header=None) # no headers in this dataset\n",
    "\n",
    "#Defining column names\n",
    "data.columns = ['target', 'ids', 'date', 'flag', 'user', 'text'] # inserting header names\n",
    "data.head() # show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87045298",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87045298",
    "outputId": "5c177b01-f65b-4d94-a3a9-9b3a199bb0f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].size # show number of records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925394c9",
   "metadata": {
    "id": "925394c9"
   },
   "source": [
    "### 3. Pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d5a974",
   "metadata": {},
   "source": [
    "As the Sentiment140 is a large dataset of tweets extracted using the twitter api, pre-processing was\n",
    "extremely important as it is required before the data can be used for analysis, to clean emojis, tags and\n",
    "other features that would impact the performance of the models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e7b31c",
   "metadata": {
    "id": "48e7b31c"
   },
   "source": [
    "##### 3.1 Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f353bec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f353bec",
    "outputId": "ecfdd593-aa3b-4ea8-f5a5-25c10cf96ffd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "ids       0\n",
       "date      0\n",
       "flag      0\n",
       "user      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cf2d04",
   "metadata": {
    "id": "50cf2d04"
   },
   "source": [
    "Comment: No missing values across all variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1af3a",
   "metadata": {
    "id": "4ec1af3a"
   },
   "source": [
    "##### 3.2 Review class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d421f257",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d421f257",
    "outputId": "ae6b854f-61af-4df8-f131-7ec52ebbd5b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800000\n",
       "4    800000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a4dc66",
   "metadata": {
    "id": "17a4dc66"
   },
   "source": [
    "Comment: labels show a 50/50 split with only 0 = neg and 4 = positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c5db9d",
   "metadata": {
    "id": "a0c5db9d"
   },
   "source": [
    "##### 3.3 Relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d54c519",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d54c519",
    "outputId": "c04b2589-2b6e-4df7-836a-0a80c68864a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO_QUERY    1600000\n",
       "Name: flag, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['flag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116af16e",
   "metadata": {
    "id": "116af16e"
   },
   "source": [
    "Comment: 'flag' column only shows one value = \"NO_QUERY\" making this variable redundant. 'date', 'user' and 'ids' also not in scope for sentiment analysis, drop also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b575615",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "7b575615",
    "outputId": "a081703c-3631-4a01-b6ed-9c1f01219eec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6c87dd20-4824-4890-9ab9-cdb1143a7fec\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c87dd20-4824-4890-9ab9-cdb1143a7fec')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6c87dd20-4824-4890-9ab9-cdb1143a7fec button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6c87dd20-4824-4890-9ab9-cdb1143a7fec');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1       0  is upset that he can't update his Facebook by ...\n",
       "2       0  @Kenichan I dived many times for the ball. Man...\n",
       "3       0    my whole body feels itchy and like its on fire \n",
       "4       0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['ids', 'date', 'flag', 'user'], axis=1) # drop columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a5454e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a5454e5",
    "outputId": "dceb4651-2af2-4753-8443-f4d4bd1375fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e147be5",
   "metadata": {
    "id": "0e147be5"
   },
   "source": [
    "##### 3.4 Cleaning & Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6120a675",
   "metadata": {
    "id": "6120a675"
   },
   "source": [
    "After dropping unnecessary columns, common abbreviations and non-English words such as ‚ÄòLOL‚Äô,\n",
    "‚Äòbday‚Äô, ‚Äòhahaha‚Äô, were replaced with a descriptive word to reduce the number of text features present.\n",
    "Stop words were used to identify and remove commonly used insignificant words that\n",
    "contain low-level information such as ‚Äòis‚Äô, ‚Äòthe‚Äô and ‚Äòin‚Äô. \n",
    "\n",
    "The removal of stop words gives the model\n",
    "more focus on words with more contextual importance, and the decrease of features will increase the\n",
    "speed of training models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6981a0c",
   "metadata": {
    "id": "d6981a0c"
   },
   "outputs": [],
   "source": [
    "#Cleaning non-english words and replacing them for its true meaning\n",
    "\n",
    "def further_cleaning(tweet):\n",
    "    message = []\n",
    "    \n",
    "    for i in tweet.split():            \n",
    "        \n",
    "        #Replacing LOL for laugh\n",
    "        if i == 'LOL':\n",
    "            replace = i.replace('LOL', 'laugh')\n",
    "            message.append(replace)\n",
    "            \n",
    "            \n",
    "        elif i == 'ugh':\n",
    "            replace = i.replace('ugh', 'disgust')\n",
    "            message.append(replace)\n",
    "            \n",
    "\n",
    "        else:\n",
    "            message.append(i)\n",
    "        \n",
    "    \n",
    "    return \" \".join(message)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7332f314",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7332f314",
    "outputId": "0f7e4694-fd35-494c-dc02-97b182623634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal : ooooh.... LOL  that leslie.... and ok I won't do it again so leslie won't  get mad again \n",
      "\n",
      "Preprocessed : ooooh.... laugh that leslie.... and ok I won't do it again so leslie won't get mad again\n"
     ]
    }
   ],
   "source": [
    "#Comparing, before and after the cleaning process\n",
    "\n",
    "print(f\"Orignal : {data.text[28]}\")\n",
    "print()\n",
    "print(f\"Preprocessed : {further_cleaning(data.text[28])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f63c71b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f63c71b7",
    "outputId": "101c2587-1b3b-44fe-c2f8-69bb5d5232b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          is upset that he can't update his Facebook by ...\n",
       "2          @Kenichan I dived many times for the ball. Man...\n",
       "3             my whole body feels itchy and like its on fire\n",
       "4          @nationwideclass no, it's not behaving at all....\n",
       "                                 ...                        \n",
       "1599995    Just woke up. Having no school is the best fee...\n",
       "1599996    TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997    Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998    Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999    happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "Name: text, Length: 1600000, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying the replacing process in the dataset\n",
    "\n",
    "data.text = data.text.apply(lambda x: further_cleaning(x))\n",
    "data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee02d2d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee02d2d0",
    "outputId": "66be2bd8-2f2f-4093-87a5-c51dd1a3e004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ooooh.... laugh that leslie.... and ok I won't do it again so leslie won't get mad again\n"
     ]
    }
   ],
   "source": [
    "print(data.text[28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e13dd6f",
   "metadata": {
    "id": "4e13dd6f"
   },
   "outputs": [],
   "source": [
    "#Further cleaning of non-english words and abbreviations\n",
    "\n",
    "def cleaning(tweet):\n",
    "    message = []\n",
    "    \n",
    "    for i in tweet.split():\n",
    "        if i == 'hahaha' or i == 'hahah' or i == 'hahahaha' or i == 'hehehe':\n",
    "            replace = i.replace(i, 'laugh')\n",
    "            message.append(replace)\n",
    "            \n",
    "            #bday will be replaced for birthday in the entire dataset\n",
    "        elif i == 'bday':\n",
    "            replace = i.replace('bday', 'birthday')\n",
    "            message.append(replace)\n",
    "            \n",
    "        else:\n",
    "            message.append(i)\n",
    "        \n",
    "    \n",
    "    return \" \".join(message)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af015fb7",
   "metadata": {
    "id": "af015fb7"
   },
   "outputs": [],
   "source": [
    "data.text = data.text.apply(lambda x: cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dabd99bc",
   "metadata": {
    "id": "dabd99bc"
   },
   "outputs": [],
   "source": [
    "#Removing stop words such as 'me', 'my'.. and stemmer to cut the end the words such as trying -> try\n",
    "stopwords = stopwords.words('english')\n",
    "stemming = SnowballStemmer('english')\n",
    "\n",
    "\n",
    "#Clean urls and tags\n",
    "clean = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "\n",
    "def data_preprocessing(message, stem = False):\n",
    "    \n",
    "    \n",
    "    message = re.sub(clean, ' ', str(message).lower()).strip() \n",
    "    text = []\n",
    "    \n",
    "    for i in message.split():\n",
    "        if i not in stopwords:\n",
    "            if stem:\n",
    "                text.append(stemming.stem(i).lower())\n",
    "            else:\n",
    "                text.append(i.lower())\n",
    "                \n",
    "    return \" \".join(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5884c702",
   "metadata": {},
   "source": [
    "Comment:\n",
    "Stemming reduces different forms of\n",
    "a word to their basic form as inflected forms create various versions of the same word which could\n",
    "produce less effective trained models. I have used the snowball technique for stemming which\n",
    "transforms words such as running, to runner, to run, and trying to try, and generously to generous. In\n",
    "addition to stop word and stemming techniques, the text corpus was also converted to lowercase to avoid \n",
    "the overlap of words with different casing patterns. The dataset was then cleaned of tags, symbols and\n",
    "punctuations such as ‚Äò@‚Äô, ‚Äò/http‚Äô and ‚Äò,‚Äô."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "547d3b88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "547d3b88",
    "outputId": "9ea6fd29-80cc-4d00-c0df-3f151992f9ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal : @LOLTrish hey long time no see! Yes.. Rains a bit ,only a bit laugh , I'm fine thanks , how's you ?\n",
      "\n",
      "Preprocessed : hey long time see yes rains bit bit laugh fine thanks\n"
     ]
    }
   ],
   "source": [
    "#Comparing the original dataset with the cleaned one\n",
    "\n",
    "print(f\"Orignal : {data.text[7]}\")\n",
    "print()\n",
    "print(f\"Preprocessed : {data_preprocessing(data.text[7])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20446501",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20446501",
    "outputId": "66db090f-5f6b-4e79-e89b-61d23fb75a2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               awww bummer shoulda got david carr third day\n",
       "1          upset update facebook texting might cry result...\n",
       "2          dived many times ball managed save 50 rest go ...\n",
       "3                           whole body feels itchy like fire\n",
       "4                                           behaving mad see\n",
       "                                 ...                        \n",
       "1599995                        woke school best feeling ever\n",
       "1599996             thewdb com cool hear old walt interviews\n",
       "1599997                      ready mojo makeover ask details\n",
       "1599998    happy 38th birthday boo alll time tupac amaru ...\n",
       "1599999    happy charitytuesday thenspcc sparkscharity sp...\n",
       "Name: text, Length: 1600000, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying the cleaned text in the dataset\n",
    "\n",
    "data_text = data.text.apply(lambda x: data_preprocessing(x))\n",
    "data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b04472c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b04472c",
    "outputId": "1f12d4d0-9622-4ffb-ad45-abb2cc94296b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "          ..\n",
       "1599995    4\n",
       "1599996    4\n",
       "1599997    4\n",
       "1599998    4\n",
       "1599999    4\n",
       "Name: target, Length: 1600000, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking target values\n",
    "data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25ebc631",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25ebc631",
    "outputId": "f73b986f-23c8-4c77-ae97-e6b00dcc8dc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 4: 1}\n"
     ]
    }
   ],
   "source": [
    "#Defining binary classes like 0 = 0 and 4 = 1\n",
    "\n",
    "binary_class = set(data.target)\n",
    "index = dict((a, b) for b, a in enumerate(binary_class))\n",
    "index_to_class = dict((c, d) for d, c in index.items())\n",
    "\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38e423ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38e423ee",
    "outputId": "55f769c8-c9cc-424e-f46b-eee73ddbccb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Changing in the dataset the classes\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "ids = lambda labels: np.array([index.get(x) for x in labels])\n",
    "\n",
    "labels = ids(data.target)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5303610",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5303610",
    "outputId": "eff754c2-4d49-4868-ddce-c6188b5cc4ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bbb7067",
   "metadata": {
    "id": "7bbb7067"
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_text, labels, test_size=0.25,\n",
    "                                                    random_state=23) # so we get the same results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee7ede7",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e7615e",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency - Inverse Document Frequency) is a handy algorithm that uses the frequency of words to determine how relevant those words are to a given document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0e368dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0e368dd",
    "outputId": "28413da1-5133-4ad6-a59d-b48a82c805ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n"
     ]
    }
   ],
   "source": [
    "# tranforming the tweet data into vectors matrix\n",
    "\n",
    "trans_vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000, lowercase= False)\n",
    "trans_vectoriser.fit(X_train)\n",
    "print(len(trans_vectoriser.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01f42420",
   "metadata": {
    "id": "01f42420"
   },
   "outputs": [],
   "source": [
    "#Transforming X_train and X_test \n",
    "\n",
    "X_train_v = trans_vectoriser.transform(X_train)\n",
    "X_test_v  = trans_vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ca12d7",
   "metadata": {},
   "source": [
    "#  4. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9513d",
   "metadata": {},
   "source": [
    "The logistic regression classifier uses the weighted\n",
    "combination of words and passes the numerical inputs to a value between 0 and 1 through the sigmoid\n",
    "function. \n",
    "\n",
    "Logistic regression is known for its easy implementation, interpretability and efficiency in\n",
    "training, in addition to the fact that the dataset is linearly separable, it makes it a great starter algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35e26294",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35e26294",
    "outputId": "ab09e78f-0069-4fe3-d08e-56fe43ba8fb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "#Creating logistic regression as the first model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "log_r = LogisticRegression(max_iter = 2000)\n",
    "log_r.fit(X_train_v, y_train)\n",
    "\n",
    "#Predicting the trained model with the test dataset\n",
    "log_pred = log_r.predict(X_test_v)\n",
    "print(\"Model accuracy: {:.2f}\".format(accuracy_score(y_test, log_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab65ee9",
   "metadata": {},
   "source": [
    "### 4.1 Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b1c76e",
   "metadata": {},
   "source": [
    "To improve the model, grid search was used for hyperparameter tuning where all possible\n",
    "combinations of the relevant hyperparameter values are tested to produce the highest accuracy. More\n",
    "specifically, for logistic regression these are the inverse of regularization strength (C), the type of\n",
    "regularization (penalty). \n",
    "\n",
    "The value of C influences the model in the way that it controls the regularization\n",
    "to avoid overfitting the model. The value of penalty could serve two purposes; L1 helps with sparsity and\n",
    "L2 aids in finding the optimal parameter ùúÜ (lambda) (17). As L2 works best with prediction, this is preset\n",
    "in parameters. We then allowed the grid search to test three combinations of C, using a cross validation\n",
    "technique with 5 folds which returned C = 1.0 as the preferred value. This produced an accuracy of\n",
    "0.7913 which is barely a noticeable difference from the pre-tuned model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a5414d",
   "metadata": {
    "id": "64a5414d",
    "outputId": "9d466589-147f-46fc-c236-ba0f2e47ac56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best parameters\n",
      "{'C': 1.0, 'penalty': 'l2'}\n",
      "0.7912681598985829\n",
      "Accuracy:0.79\n"
     ]
    }
   ],
   "source": [
    "#HYPERPARAMETER TUNING\n",
    "#Gridsearch for Logistic Regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'penalty':['l2'],\n",
    "                'C':np.logspace(0, 3, 7)\n",
    "                }\n",
    "logistic_r = LogisticRegression(max_iter = 2000, n_jobs=-1)\n",
    "\n",
    "logis_cv = GridSearchCV(logistic_r, param_grid, cv=5, verbose=1)\n",
    "logis_cv.fit(X_train_v, y_train)\n",
    "\n",
    "lr_score = logis_cv.score(X_test_v, y_test)\n",
    "print(\"Best parameters\")\n",
    "print(logis_cv.best_params_)\n",
    "print(logis_cv.best_score_)\n",
    "print(\"Accuracy:{:.2f}\".format(lr_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9310e1",
   "metadata": {
    "id": "3d9310e1",
    "outputId": "7bbc4e70-6e23-4ec0-cd21-b370e3a37238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79    200309\n",
      "           4       0.78      0.81      0.80    199691\n",
      "\n",
      "    accuracy                           0.79    400000\n",
      "   macro avg       0.79      0.79      0.79    400000\n",
      "weighted avg       0.79      0.79      0.79    400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Getting results from the tuned model\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "predict = logis_cv.predict(X_test_v)\n",
    "print(\"Results:\\n{}\".format(metrics.classification_report(y_test, predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d3550",
   "metadata": {
    "id": "c40d3550"
   },
   "source": [
    "# 5. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f489c",
   "metadata": {},
   "source": [
    "### 5.1 Pre-processing for Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a500a4",
   "metadata": {},
   "source": [
    "For NN, tokenization and padding was applied. Tokenization is the process of breaking text\n",
    "into smaller units called tokens which aids in interpreting the meaning of sentences by analysing the\n",
    "sequence of words. For example, ‚Äòwhat a beautiful code‚Äô would be split into tokens of ‚Äòwhat‚Äô, ‚Äòa‚Äô,\n",
    "‚Äòbeautiful‚Äô, ‚Äòcode‚Äô. Padding then adds zeros at the end of the sequences to match up the size of each\n",
    "sample. As not all sequences have the same number of words, this is applied to ensure the data can be fed\n",
    "into our neural network models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9ea596e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9ea596e",
    "outputId": "c800f366-6239-465e-d276-771da8a4163c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[342, 1062, 3367, 12, 721, 9502, 1767, 3]]\n"
     ]
    }
   ],
   "source": [
    "#Tokenization for NN\n",
    "\n",
    "tokenizer = Tokenizer(num_words=100000, oov_token='<UNK>')\n",
    "\n",
    "tokenizer.fit_on_texts(data_text)\n",
    "\n",
    "print(tokenizer.texts_to_sequences([data_text[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d560d6b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d560d6b0",
    "outputId": "11ca3410-2591-4b16-a06c-40e3bd77980b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335374"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cheking the word index length\n",
    "\n",
    "len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ba0b4b4",
   "metadata": {
    "id": "7ba0b4b4"
   },
   "outputs": [],
   "source": [
    "#Padding the model, to make sure that the length are the same\n",
    "\n",
    "def getting_sequences(tokenizer, message):\n",
    "    text_seq= tokenizer.texts_to_sequences(message)\n",
    "    pad_seq = pad_sequences(text_seq, truncating='post', maxlen=100, padding='post')\n",
    "    return pad_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffa7706a",
   "metadata": {
    "id": "ffa7706a"
   },
   "outputs": [],
   "source": [
    "#Applying padding\n",
    "\n",
    "data_text_seq = getting_sequences(tokenizer, data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35e9484d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35e9484d",
    "outputId": "e6ed4a30-7b0a-4f6e-a422-16a7b8ce7baa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  694,   233,  5576, 21272,   170,   219,  2828,   219,  7551,\n",
       "          233,  5576,  1751,   170,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0], dtype=int32),\n",
       " array([ 3396, 64805,  1308,    51,   348, 14321,  2471,   386,  1412,\n",
       "         2344,   203,  4562,    53,   164,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0], dtype=int32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the sequences to see the pad, 0 will be added to reach the maxlen set to 100\n",
    "\n",
    "data_text_seq[100], data_text_seq[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9cfd9c6",
   "metadata": {
    "id": "d9cfd9c6"
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets for the NN models\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_text_seq, labels, test_size=0.25,\n",
    "                                                    random_state=23) # so we get the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6fc8d68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6fc8d68",
    "outputId": "9a59e999-1c69-4d7e-844f-958e434c4374"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   64,     5,  2348, ...,     0,     0,     0],\n",
       "       [   60,   168,   362, ...,     0,     0,     0],\n",
       "       [   82,   398,   149, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [   32,   633,     1, ...,     0,     0,     0],\n",
       "       [41822,  4631,   536, ...,     0,     0,     0],\n",
       "       [   31,  9749,   315, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e95d330",
   "metadata": {
    "id": "6e95d330"
   },
   "source": [
    "### 5.2 LSMT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe27e6e",
   "metadata": {},
   "source": [
    "The LSTM model was built using TensorFlow and Keras. I used a sequential keras model and stated\n",
    "the first Embedding layer with word embedding, which maps each word to a dimensional space and it\n",
    "receives a real-valued vector to get a dense representation of words and their relative meaning. I have\n",
    "defined the Embedding layer with a vocabulary of 100,000 and a vector space of 100 dimensions.\n",
    "\n",
    "For the LSTM layers it was decided to use bidirectional instead of the regular layer, for the fact\n",
    "that bidirectional allows input to flow in two directions. It is useful for text classification as it trains\n",
    "two sides of the input sequence, facilitating to fit the word in the right context. Therefore, two layers were\n",
    "defined as it is more suitable to detect complex features, where the first and the second bidirectional\n",
    "layers were defined with 64 units. \n",
    "Sigmoid activation function was used in the final output layer as sigmoid performs better for binary\n",
    "classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "tqWjhfy8qc5X",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tqWjhfy8qc5X",
    "outputId": "fbbb26bd-ab5b-4e11-d24b-267926983985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         10000000  \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 128)        84480     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,183,425\n",
      "Trainable params: 10,183,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Building LSTM model\n",
    "\n",
    "model_1 = tf.keras.models.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Embedding(100000, 100),\n",
    "    \n",
    "    #Bidirectional layers\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    \n",
    "    #Final output layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9P0E86FUqmfQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9P0E86FUqmfQ",
    "outputId": "0d4fc0d4-72ff-4e63-acd9-5afcf2f5fedb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "8438/8438 [==============================] - 282s 32ms/step - loss: 0.4653 - accuracy: 0.7769 - val_loss: 0.4440 - val_accuracy: 0.7906\n",
      "Epoch 2/4\n",
      "8438/8438 [==============================] - 269s 32ms/step - loss: 0.4178 - accuracy: 0.8058 - val_loss: 0.4452 - val_accuracy: 0.7895\n",
      "Epoch 3/4\n",
      "8438/8438 [==============================] - 272s 32ms/step - loss: 0.3789 - accuracy: 0.8274 - val_loss: 0.4623 - val_accuracy: 0.7871\n",
      "Epoch 4/4\n",
      "8438/8438 [==============================] - 272s 32ms/step - loss: 0.3336 - accuracy: 0.8507 - val_loss: 0.4958 - val_accuracy: 0.7793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f69e3c1ba90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compiling the model\n",
    "model_1.compile(\"adam\", \"binary_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "#Fitting the model in the train dataset\n",
    "model_1.fit(X_train, y_train, validation_split=0.1, batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc27d52",
   "metadata": {
    "id": "aC0h3iuXqtFD"
   },
   "source": [
    "###  5.3 Hyperparameter tuning with Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f027b19f",
   "metadata": {},
   "source": [
    "From Keras tuner, hyperband tuning was the selected method as it trains a considerable number of\n",
    "models for a few epochs and continues training the best performing models on the validation set.\n",
    "\n",
    "Hyperband was set with a maximum epoch of 10, validation accuracy as the objective and an early stop\n",
    "callback was set to monitor validation loss and stop training when reaching a certain value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64f55266",
   "metadata": {
    "id": "64f55266"
   },
   "outputs": [],
   "source": [
    "# Defining the structure of the model to tune it\n",
    "\n",
    "def lstm_model(hp):\n",
    "    model_lstm = Sequential()\n",
    "    \n",
    "    model_lstm.add(tf.keras.layers.Embedding(100000, 100)),\n",
    "    \n",
    "    #adding dropout to avoid overfitting  \n",
    "    #and Hp.float, allows the algorithms to try different dropout rates\n",
    "    model_lstm.add(tf.keras.layers.Dropout(hp.Float('Dropout_rate',min_value=0,max_value=0.5,step=0.25)))\n",
    "    \n",
    "    model_lstm.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))),\n",
    "\n",
    "    \n",
    "    #Adding another dropout layer to avoid overfitting\n",
    "    model_lstm.add(tf.keras.layers.Dropout(hp.Float('Dropout_rate',min_value=0,max_value=0.5,step=0.25)))\n",
    "               \n",
    "                   \n",
    "    model_lstm.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128))),\n",
    "\n",
    "                \n",
    "    model_lstm.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compiling the model and tuning learning rate\n",
    "    model_lstm.compile(\n",
    "    optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-3, 1e-4])), \n",
    "        loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39fee366",
   "metadata": {
    "id": "39fee366"
   },
   "outputs": [],
   "source": [
    "#Tuning the parameters with Hyperband with objective set as validation accuracy\n",
    "\n",
    "tuner_lstm = kt.Hyperband(lstm_model,\n",
    "                     #overwrite=True,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='tuning_kt'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40fc7479",
   "metadata": {
    "id": "40fc7479"
   },
   "outputs": [],
   "source": [
    "#Appying early stop to avoid overfitting\n",
    "\n",
    "stop_lstm = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "_B74RpGiUb5E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_B74RpGiUb5E",
    "outputId": "6ea059ee-3eed-453e-c309-10f5672b6451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 20m 38s]\n",
      "val_accuracy: 0.7873166799545288\n",
      "\n",
      "Best val_accuracy So Far: 0.7934583425521851\n",
      "Total elapsed time: 02h 04m 21s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The opimized dropout rate is 0.25 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tuning and searching for best parameters\n",
    "\n",
    "tuner_lstm.search(X_train,y_train,epochs=20, batch_size=64, validation_split=0.1, callbacks = [stop_lstm])\n",
    "\n",
    "#getting the 1st model with best performance\n",
    "model_tun_lstm = tuner_lstm.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The opimized dropout rate is {model_tun_lstm.get('Dropout_rate')} and the optimal learning rate for the optimizer\n",
    "is {model_tun_lstm.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "VqUAhbUpnyFJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VqUAhbUpnyFJ",
    "outputId": "d345aed0-2e51-4cb8-9c91-e150754a4c72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "33750/33750 [==============================] - 1073s 32ms/step - loss: 0.4648 - accuracy: 0.7778 - val_loss: 0.4450 - val_accuracy: 0.7915\n",
      "Epoch 2/5\n",
      "33750/33750 [==============================] - 1088s 32ms/step - loss: 0.4217 - accuracy: 0.8044 - val_loss: 0.4399 - val_accuracy: 0.7935\n",
      "Epoch 3/5\n",
      "33750/33750 [==============================] - 1112s 33ms/step - loss: 0.3898 - accuracy: 0.8235 - val_loss: 0.4579 - val_accuracy: 0.7887\n",
      "Epoch 4/5\n",
      "33750/33750 [==============================] - 1114s 33ms/step - loss: 0.3613 - accuracy: 0.8386 - val_loss: 0.4750 - val_accuracy: 0.7839\n",
      "Epoch 5/5\n",
      "33750/33750 [==============================] - 1110s 33ms/step - loss: 0.3423 - accuracy: 0.8478 - val_loss: 0.4970 - val_accuracy: 0.7781\n",
      "Best epoch is: 2\n"
     ]
    }
   ],
   "source": [
    "# Build the tuned model and check the optimal number of epochs\n",
    "model_ep = tuner_lstm.hypermodel.build(model_tun_lstm)\n",
    "history = model_ep.fit(X_train, y_train, epochs=5, validation_split=0.1)\n",
    "\n",
    "#Optmial number of epochs\n",
    "val_epoch = history.history['val_accuracy']\n",
    "tuned_epoch = val_epoch.index(max(val_epoch)) + 1\n",
    "print('Best epoch is: %d' % (tuned_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ZyThxI3dpWdq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZyThxI3dpWdq",
    "outputId": "47f7eeb4-5022-4b3f-a4ed-0ac92cba0403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 143s 11ms/step - loss: 0.5394 - accuracy: 0.7737\n"
     ]
    }
   ],
   "source": [
    "#Predicting in the test dataset \n",
    "acc_lstm = model_ep.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5621a",
   "metadata": {
    "id": "76a5621a"
   },
   "source": [
    "### 5.4 CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7300081",
   "metadata": {},
   "source": [
    "To set up the CNN model, 1D convolutions were used to scan through the sequence of words rather than\n",
    "2D, which is most commonly used for image classification.\n",
    "\n",
    "The model was created with 1D\n",
    "convolutional layer, with 128 units, kernel size defined to 5 and activation ‚Äòrelu‚Äô. A global max pooling\n",
    "1D was added in order to downsample the input representation, followed by the final output layer with\n",
    "first a dense layer with value set to 10 and activation ‚Äòrelu‚Äô which is a non-linear activation function, and\n",
    "lastly the sigmoid activation dense layer as it is a binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b2146ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b2146ae",
    "outputId": "93a1d73d-8e04-4211-a454-2d4905113dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size : 335374\n"
     ]
    }
   ],
   "source": [
    "#word_index = tokenizer.word_index\n",
    "len_voca = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary Size :\", len_voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3918955",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3918955",
    "outputId": "b7a3abfe-00cf-4751-db62-d0af5ac25449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 100, 200)          67074800  \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 96, 128)           128128    \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,204,229\n",
      "Trainable params: 67,204,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Defining the parameters for the CNN model\n",
    "\n",
    "embedding_dim = 200\n",
    "maxlen=100\n",
    "model_cnn = Sequential()\n",
    "\n",
    "#Embending layer\n",
    "model_cnn.add(layers.Embedding(len_voca, embedding_dim, input_length=maxlen))\n",
    "\n",
    "#Convolutional layer\n",
    "model_cnn.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "\n",
    "#Pooling with max pooling1D\n",
    "model_cnn.add(layers.GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer with relu\n",
    "model_cnn.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "#Sigmoid Final output layer\n",
    "model_cnn.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Compiling the model\n",
    "model_cnn.compile(optimizer='adam',\n",
    "           loss='binary_crossentropy',\n",
    "           metrics=['accuracy'])\n",
    "model_cnn.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc49e066",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bc49e066",
    "outputId": "9c010011-385c-4220-9611-8954d7a2316c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8438/8438 [==============================] - 197s 22ms/step - loss: 0.4634 - accuracy: 0.7778 - val_loss: 0.4438 - val_accuracy: 0.7906\n",
      "Epoch 2/3\n",
      "8438/8438 [==============================] - 189s 22ms/step - loss: 0.3983 - accuracy: 0.8177 - val_loss: 0.4499 - val_accuracy: 0.7904\n",
      "Epoch 3/3\n",
      "8438/8438 [==============================] - 189s 22ms/step - loss: 0.3227 - accuracy: 0.8585 - val_loss: 0.4953 - val_accuracy: 0.7792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f69d2b45e90>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the model with 3 epochs and batch size = 128 so the model can train faster\n",
    "\n",
    "EPOCHS=3\n",
    "BATCH_SIZE=128\n",
    "\n",
    "model_cnn.fit(X_train, y_train,\n",
    "          epochs=EPOCHS, \n",
    "          validation_split=0.1,\n",
    "          batch_size=BATCH_SIZE, \n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e359d7aa",
   "metadata": {},
   "source": [
    "### 5.5 Hyperparameter tuning for CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7d2d3c",
   "metadata": {},
   "source": [
    "For the tuning process, random search from Keras Tuner was used instead of Hyperband that was\n",
    "previously used to tune LSTM. Random search uses different values to find the best parameters to build\n",
    "the optimized model.\n",
    "\n",
    "Max trial represents the number of model configurations to be tested. In the first trial the algorithm\n",
    "will run with a combination of convolutional layers units of 128, kernel size of 5, dropout rate of 0.25,\n",
    "dense units of 10 and a learning rate of 0.001. The second trial will then combine different values and at\n",
    "the end the model will be re-defined with the values that provided the best validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "PcH88DPmINHu",
   "metadata": {
    "id": "PcH88DPmINHu"
   },
   "outputs": [],
   "source": [
    "# generating validation set\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "75a6e515",
   "metadata": {
    "id": "75a6e515"
   },
   "outputs": [],
   "source": [
    "#Tuning the parameters for CNN\n",
    "\n",
    "embedding_dim = 200\n",
    "\n",
    "def tuning_model(hp):\n",
    "    model_h = Sequential()\n",
    "    model_h.add(layers.Embedding(len_voca, embedding_dim, input_length=100))\n",
    "    \n",
    "    # Random search will test different filter values and kernel sizes\n",
    "    model_h.add(layers.Conv1D(filters=hp.Int('filters',\n",
    "                                        min_value=64,\n",
    "                                        max_value=128,\n",
    "                                        step = 64),\n",
    "                kernel_size=hp.Choice('conv_1_filter', values = [3,5]), activation='relu'))\n",
    "    \n",
    "    model_h.add(layers.GlobalMaxPooling1D())\n",
    "    \n",
    "    #Dropout layer was added to avoid overfitting, and random search will try different values as showing bellow\n",
    "    model_h.add(layers.Dropout(rate=hp.Float('dropout_1', min_value = 0.0, max_value = 0.5, default=0.25, step=0.25,)))\n",
    "    \n",
    "    \n",
    "    model_h.add(layers.Dense(units=hp.Int('units',\n",
    "                                        min_value=10,\n",
    "                                        max_value=20,\n",
    "                                        step=10),\n",
    "                           activation='relu'))\n",
    "    \n",
    "    model_h.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #Compiling the model\n",
    "    model_h.compile(\n",
    "    optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])), \n",
    "        loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "80135b7b",
   "metadata": {
    "id": "80135b7b"
   },
   "outputs": [],
   "source": [
    "#Random search will find the best model/parameters\n",
    "\n",
    "tuner = RandomSearch(tuning_model,\n",
    "                     #overwrite=True,\n",
    "                     objective='val_accuracy',\n",
    "                     max_trials = 4,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='cnn_model'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa3ee23e",
   "metadata": {
    "id": "fa3ee23e"
   },
   "outputs": [],
   "source": [
    "#Appying early stop to monitor the validation loss and stop the model\n",
    "\n",
    "stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f93c05f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f93c05f",
    "outputId": "c0bd94fb-0941-4fa0-926e-9aeba985539f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [00h 12m 30s]\n",
      "val_accuracy: 0.7889083623886108\n",
      "\n",
      "Best val_accuracy So Far: 0.7889083623886108\n",
      "Total elapsed time: 00h 49m 53s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 200)          67074800  \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 98, 128)           76928     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,153,029\n",
      "Trainable params: 67,153,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# tuning and seraching for best parameters\n",
    "\n",
    "tuner.search(X_train,y_train,epochs=4, batch_size=128, callbacks = [stop],\n",
    "             validation_data = (X_valid, y_valid))\n",
    "model_tun = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "#summary of best model\n",
    "model_tun.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "52092182",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52092182",
    "outputId": "bc10e780-c7f5-4ff6-b27a-95284b74b23a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 30s 2ms/step - loss: 0.4431 - accuracy: 0.7911\n"
     ]
    }
   ],
   "source": [
    "#Predicting with the test data set\n",
    "accuracy = model_tun.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c13932c",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f1aed",
   "metadata": {},
   "source": [
    "There is great potential in future improvements with investigating other pre-processing steps to\n",
    "optimise the models. \n",
    "\n",
    "For cleaning in particular, the removal of non-English words and abbreviations.\n",
    "Other areas include the use of other word embedding tools such as Glove or Word2Vec. Additionally,\n",
    "several other model architectures for Long-short term memory (LSTM) and Convolutional neural network\n",
    "(CNN) could be trialed and tested, which may improve the model‚Äôs performance.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ML Assignment 2 - NN models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
